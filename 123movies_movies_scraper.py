import asyncio
from playwright.async_api import async_playwright
import json
from datetime import datetime
import re

async def scrape_123movies_direct(max_pages=None):
    all_movies = []
    # Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù„ÙŠ vumoo Ø¨ÙŠØ¹Ø±Ø¶Ù‡
    base_url = "https://ww8.123moviesfree.net/movie/"
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        
        current_page = 1
        while True:
            if max_pages is not None and current_page > max_pages:
                break
                
            url = f"{base_url}?page={current_page}"
            print(f"ğŸ“¡ Ø³Ø­Ø¨ ØµÙØ­Ø© {current_page} Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±...")
            
            try:
                response = await page.goto(url, wait_until="domcontentloaded", timeout=60000)
                if response.status == 404: break

                # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø³ÙŠØ· Ù„Ø¶Ù…Ø§Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ±
                await asyncio.sleep(2)

                # Ø§Ù„Ø³ÙŠÙ„ÙƒØªÙˆØ±Ø² Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù„ÙŠ Ø¨Ø¹ØªÙ‡ (card h-100)
                items = await page.query_selector_all('div.col')
                if not items: break

                for item in items:
                    try:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
                        title_tag = await item.query_selector('h2.card-title')
                        if not title_tag: continue
                        title = await title_tag.inner_text()

                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø·
                        link_tag = await item.query_selector('a.poster')
                        href = await link_tag.get_attribute('href')

                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© (Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø¨ÙŠØ³ØªØ®Ø¯Ù… lazy loading)
                        img_tag = await item.query_selector('img')
                        image_url = ""
                        if img_tag:
                            image_url = await img_tag.get_attribute('data-src') or \
                                        await img_tag.get_attribute('src')

                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù†Ø© Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¥Ù† ÙˆØ¬Ø¯Øª
                        year_match = re.search(r'(\d{4})', title)
                        year = int(year_match.group(1)) if year_match else 2025

                        all_movies.append({
                            "name": f"[123Movies] {title.strip()}",
                            "url": href if href.startswith('http') else f"https://ww8.123moviesfree.net{href}",
                            "image_url": image_url,
                            "year": year,
                            "genre": "Movies",
                            "rating": 0.0,
                            "createdAt": datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
                        })
                    except: continue
                
                print(f"âœ… ØªÙ… Ø¬Ù…Ø¹ {len(items)} ÙÙŠÙ„Ù… Ù…Ù† ØµÙØ­Ø© {current_page}")
                current_page += 1
                
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØµÙØ­Ø© {current_page}: {e}")
                break

        if all_movies:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
            unique_movies = list({m['url']: m for m in all_movies}.values())
            # ØªÙ‚Ø³ÙŠÙ… ÙˆØ­ÙØ¸ (Chunks) Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªØ®Ø·ÙŠ Ù…Ø³Ø§Ø­Ø© GitHub
            chunk_size = 10000
            for i in range(0, len(unique_movies), chunk_size):
                chunk = unique_movies[i : i + chunk_size]
                part = (i // chunk_size) + 1
                filename = f"123movies_part{part}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(chunk, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(chunk)} ÙÙŠÙ„Ù… ÙÙŠ {filename}")

        await browser.close()

if __name__ == "__main__":
    # Ø¬Ø±Ø¨ ØªØ³Ø­Ø¨ Ø£ÙˆÙ„ 5 ØµÙØ­Ø§Øª ÙƒÙ…Ø«Ø§Ù„ØŒ Ø£Ùˆ None Ù„ÙƒÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹
    asyncio.run(scrape_123movies_direct())