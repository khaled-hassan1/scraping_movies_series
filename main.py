import json
import os
from datetime import datetime

def combine_and_paginate_json():
    combined_data = []
    output_file = 'all_data.json'
    db_dir = 'db' # Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ø³ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…Ø§Øª
    pages_dir = os.path.join(db_dir, 'pages')
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    if not os.path.exists(pages_dir):
        os.makedirs(pages_dir)

    # 1. Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ù„Ù…ØµØ§Ø¯Ø±
    priority_order = ["fushaar", "akoam", "laroza", "mycima", "egibest"]
    
    # Ø¬Ù„Ø¨ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ JSON (ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø© ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®ÙÙŠØ©)
    all_files = [f for f in os.listdir('.') if f.endswith('.json') 
                 and f not in [output_file, 'manifest.json'] 
                 and not f.startswith('.')]
    
    ordered_files = []
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
    for keyword in priority_order:
        temp_list = [f for f in all_files if keyword in f.lower()]
        ordered_files.extend(temp_list)
        for f in temp_list: all_files.remove(f)
    
    ordered_files.extend(all_files) # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨Ø§Ù‚ÙŠ

    # 2. Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯Ù…Ø¬
    for file in ordered_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    combined_data.extend(data)
                    print(f"âœ… ØªÙ… Ø¯Ù…Ø¬ {len(data)} Ø¹Ù†ØµØ± Ù…Ù† {file}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ {file}: {e}")

    if not combined_data:
        print("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„ÙŠÙ‡Ø§.")
        return

    # --- Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ÙˆØ§Ù„Ø¶ØºØ· Ù„Ù„Ø³Ù„Ø§Ø³Ø© Ø§Ù„ØªØ§Ù…Ø© ---

    # 3. Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù…Ø¶ØºÙˆØ·Ø© ÙˆØ¨Ø¯ÙˆÙ† Ù…Ø³Ø§ÙØ§Øª Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ù…Ø³Ø§Ø­Ø©)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(combined_data, f, ensure_ascii=False) # Ø­Ø°ÙÙ†Ø§ indent=4 Ù„ØªØµØºÙŠØ± Ø§Ù„Ø­Ø¬Ù…

    # 4. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØµÙØ­Ø§Øª (ÙƒÙ„ ØµÙØ­Ø© 300 Ø¹Ù†ØµØ±)
    page_size = 300
    total_items = len(combined_data)
    total_pages = (total_items // page_size) + (1 if total_items % page_size > 0 else 0)

    for i in range(0, total_items, page_size):
        page_num = (i // page_size) + 1
        chunk = combined_data[i : i + page_size]
        with open(f'{pages_dir}/{page_num}.json', 'w', encoding='utf-8') as f:
            json.dump(chunk, f, ensure_ascii=False) # Ø­ÙØ¸ Ø§Ù„ØµÙØ­Ø© Ù…Ø¶ØºÙˆØ·Ø©

    # 5. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ù€ Manifest (Ø§Ù„ÙÙ‡Ø±Ø³) Ø§Ù„Ø°ÙŠ ÙŠØ·Ù„Ø¨Ù‡ ÙƒÙˆØ¯ ÙÙ„Ø§ØªØ±
    manifest = {
        "total_pages": total_pages,
        "total_items": total_items,
        "last_update": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "page_size": page_size
    }
    with open(os.path.join(db_dir, 'manifest.json'), 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"ğŸ“¦ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_items} Ø¹Ù†ØµØ±.")
    print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {total_pages} ØµÙØ­Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ 'db/pages'.")
    print(f"ğŸš€ ØªÙ… Ø¶ØºØ· Ù…Ù„Ù {output_file} Ù„Ø¶Ù…Ø§Ù† Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡.")

if __name__ == "__main__":
    combine_and_paginate_json()