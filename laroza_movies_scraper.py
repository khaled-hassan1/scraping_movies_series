import asyncio
from playwright.async_api import async_playwright
import json
from datetime import datetime
import re

async def scrape_laroza_movies(max_pages_per_category=None):
    all_movies = [] 
    browser_instance = None
    blacklist = ["+18", "Ù„Ù„ÙƒØ¨Ø§Ø± ÙÙ‚Ø·", "Ø¬Ù†Ø³", "sex", "adult", "18+"]
    
    movie_categories = [
        "https://laroza.makeup/category.php?cat=all_movies_13",
        "https://laroza.makeup/category.php?cat=arabic-movies33",
        "https://laroza.makeup/category.php?cat=indian-movies9",
        "https://laroza.makeup/category.php?cat=6-asian-movies",
        "https://laroza.makeup/category.php?cat=anime-movies-7",
        "https://laroza.makeup/category.php?cat=7-aflammdblgh",
        "https://laroza.makeup/category.php?cat=8-aflam3isk",
        "https://laroza.makeup/category.php?cat=masrh-5"
    ]

    try:
        async with async_playwright() as p:
            browser_instance = await p.chromium.launch(headless=True)
            context = await browser_instance.new_context(
                viewport={'width': 1280, 'height': 1000},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
            )
            page = await context.new_page()
            
            # Ù…Ù†Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù‚ÙŠÙ„Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            # await page.route("**/*.{png,jpg,jpeg,webp,gif}", lambda route: route.abort())

            for base_url in movie_categories:
                category_name = base_url.split('=')[-1]
                current_page = 1
                
                while True:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù‚Ù Ø§Ù„ØµÙØ­Ø§Øª Ù„ÙƒÙ„ Ù‚Ø³Ù…
                    if max_pages_per_category is not None and current_page > max_pages_per_category:
                        break

                    url = f"{base_url}&page={current_page}"
                    print(f"ğŸ“¡ Ø³Ø­Ø¨ Ù‚Ø³Ù… [{category_name}] - ØµÙØ­Ø© {current_page}...")
                    
                    try:
                        response = await page.goto(url, wait_until="domcontentloaded", timeout=60000)
                        
                        if response and response.status == 404:
                            break

                        # ØªÙ…Ø±ÙŠØ± Ø¨Ø³ÙŠØ· Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù€ Lazy Load Ù„Ù„ØµÙˆØ±
                        await page.evaluate("window.scrollBy(0, 1000)")
                        await asyncio.sleep(0.5)

                        await page.wait_for_selector('li.col-xs-6', timeout=10000)
                        items = await page.query_selector_all('li.col-xs-6')

                        if not items:
                            break

                        for item in items:
                            try:
                                link_tag = await item.query_selector('h3 a')
                                if not link_tag: continue
                                
                                full_title = await link_tag.get_attribute('title')
                                if not full_title:
                                    full_title = await link_tag.inner_text()
                                
                                # ÙÙ„ØªØ± Ø§Ù„Ø£Ù…Ø§Ù†
                                if any(word in full_title.lower() for word in blacklist):
                                    continue

                                href = await link_tag.get_attribute('href')
                                img_tag = await item.query_selector('img')
                                image_url = ""
                                if img_tag:
                                    image_url = await img_tag.get_attribute('data-src') or \
                                                await img_tag.get_attribute('data-original') or \
                                                await img_tag.get_attribute('src')

                                clean_name = full_title.replace("Ù…Ø´Ø§Ù‡Ø¯Ø©", "").replace("ÙÙŠÙ„Ù…", "").replace("Ø§ÙˆÙ† Ù„Ø§ÙŠÙ†", "").replace("Ù„Ø§Ø±ÙˆØ²Ø§", "").strip()
                                year_match = re.search(r'(\d{4})', clean_name)
                                
                                all_movies.append({
                                    "name": f"[Ù„Ø§Ø±ÙˆØ²Ø§] {clean_name}",
                                    "url": href if href.startswith('http') else f"https://laroza.makeup/{href}",
                                    "image_url": image_url,
                                    "year": int(year_match.group(1)) if year_match else 2025,
                                    "genre": "Ø£ÙÙ„Ø§Ù…",
                                    "rating": 0.0,
                                    "createdAt": datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
                                })
                            except:
                                continue
                        
                        current_page += 1
                        
                    except Exception as e:
                        print(f"âš ï¸ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ù‚Ø³Ù… Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)[:40]}")
                        break 

    except asyncio.CancelledError:
        print("\nâš ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø³Ø­Ø¨ ÙŠØ¯ÙˆÙŠØ§Ù‹.. Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©...")
    except Exception as e:
        print(f"\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
    
    finally:
        if all_movies:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù†Ø§ØªØ¬ Ø¹Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙÙŠÙ„Ù… ÙÙŠ Ø£ÙƒØ«Ø± Ù…Ù† Ù‚Ø³Ù…
            unique_movies = list({m['url']: m for m in all_movies}.values())
            with open('laroza_movies.json', 'w', encoding='utf-8') as f:
                json.dump(unique_movies, f, ensure_ascii=False, indent=4)
            print(f"âœ… ØªÙ… Ø­ÙØ¸ {len(unique_movies)} ÙÙŠÙ„Ù… ÙØ±ÙŠØ¯ Ù…Ù† Ù„Ø§Ø±ÙˆØ²Ø§.")
        else:
            print("â„¹ï¸ Ù„Ù… ÙŠØªÙ… Ø¬Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª.")
            
        if browser_instance:
            await browser_instance.close()

if __name__ == "__main__":
    try:
        # Ù„Ø³Ø­Ø¨ ÙƒÙ„ Ø´ÙŠØ¡ Ø§ØªØ±ÙƒÙ‡Ø§ ÙØ§Ø±ØºØ©ØŒ Ø£Ùˆ Ø­Ø¯Ø¯ Ø±Ù‚Ù…Ø§Ù‹ Ù„Ù„ØµÙØ­Ø§Øª Ù„ÙƒÙ„ Ù‚Ø³Ù…
        asyncio.run(scrape_laroza_movies(max_pages_per_category=None))
    except KeyboardInterrupt:
        pass