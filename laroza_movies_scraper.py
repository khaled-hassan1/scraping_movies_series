import asyncio
from playwright.async_api import async_playwright
import json
from datetime import datetime
import re
import os


async def scrape_laroza_movies(max_pages_per_category=None):
    all_movies = []
    browser_instance = None  # Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¢Ù…Ù† ÙÙŠ Ø¨Ù„ÙˆÙƒ finally
    blacklist = ["+18", "Ù„Ù„ÙƒØ¨Ø§Ø± ÙÙ‚Ø·", "Ø¬Ù†Ø³", "sex", "adult", "18+"]
    base_url = "https://larozza.xyz"
    movie_categories = [
        f"{base_url}/category.php?cat=all_movies_13",
        f"{base_url}/category.php?cat=arabic-movies33",
        f"{base_url}/category.php?cat=indian-movies9",
        f"{base_url}/category.php?cat=6-asian-movies",
        f"{base_url}/category.php?cat=anime-movies-7",
        f"{base_url}/category.php?cat=7-aflammdblgh",
        f"{base_url}/category.php?cat=8-aflam3isk",
        f"{base_url}/category.php?cat=masrh-5",
    ]

    try:
        async with async_playwright() as p:
            # 1. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªØµÙØ­ Ù…Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù„ÙŠ
            browser_instance = await p.chromium.launch(headless=True)
            context = await browser_instance.new_context(
                viewport={"width": 1280, "height": 1000},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            )
            page = await context.new_page()

            # 2. Ù…Ù†Ø¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø³Ø­Ø¨ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù€ RAM
            await page.route(
                "**/*.{png,jpg,jpeg,webp,gif}", lambda route: route.abort()
            )

            for cat_url in movie_categories:
                current_page = 1
                category_name = cat_url.split("=")[-1]
                print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„ÙØ¦Ø©: {category_name}...")

                while True:
                    if (
                        max_pages_per_category is not None
                        and current_page > max_pages_per_category
                    ):
                        break

                    try:
                        # Ø§Ø³ØªØ®Ø¯Ø§Ù… wait_until="commit" Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø±Ø¹Ø©
                        await page.goto(
                            f"{cat_url}&page={current_page}",
                            wait_until="commit",
                            timeout=90000,
                        )

                        # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø³ÙŠØ· Ù„Ø¶Ù…Ø§Ù† Ø¸Ù‡ÙˆØ± Ø§Ù„Ø¹Ù†Ø§ØµØ±
                        await asyncio.sleep(1)

                        items = await page.query_selector_all("div.boxItem")
                        if not items:
                            print(
                                f"ğŸ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙØ¦Ø© {category_name} Ø¹Ù†Ø¯ ØµÙØ­Ø© {current_page-1}"
                            )
                            break

                        for item in items:
                            try:
                                title_tag = await item.query_selector("h3")
                                title = (
                                    await title_tag.inner_text() if title_tag else ""
                                )

                                if any(word in title.lower() for word in blacklist):
                                    continue

                                clean_name = (
                                    title.replace("Ù…Ø´Ø§Ù‡Ø¯Ø©", "")
                                    .replace("ÙÙŠÙ„Ù…", "")
                                    .replace("Ø§ÙˆÙ† Ù„Ø§ÙŠÙ†", "")
                                    .strip()
                                )
                                link_tag = await item.query_selector("a")
                                href = await link_tag.get_attribute("href")
                                img_tag = await item.query_selector("img")
                                image_url = await img_tag.get_attribute("src")

                                year_match = re.search(r"(\d{4})", clean_name)

                                all_movies.append(
                                    {
                                        "name": f"[Ù„Ø§Ø±ÙˆØ²Ø§] {clean_name}",
                                        "url": (
                                            href
                                            if href.startswith("http")
                                            else f"https://laroza.makeup/{href}"
                                        ),
                                        "image_url": image_url,
                                        "year": (
                                            int(year_match.group(1))
                                            if year_match
                                            else 2026
                                        ),
                                        "genre": "Ø£ÙÙ„Ø§Ù…",
                                        "rating": 0.0,
                                        "createdAt": datetime.now().strftime(
                                            "%Y-%m-%dT%H:%M:%S"
                                        ),
                                    }
                                )
                            except:
                                continue

                        print(
                            f"âœ… ÙØ¦Ø© {category_name} - ØµÙØ­Ø© {current_page}: ØªÙ… Ø¬Ù…Ø¹ {len(items)} Ø¹Ù†ØµØ±."
                        )
                        current_page += 1
                    except Exception as e:
                        print(
                            f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ¦Ø© {category_name} ØµÙØ­Ø© {current_page}: {e}"
                        )
                        break

    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: {e}")

    finally:
        # --- Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø±Ù‚Ù… 2: Ù‚ØªÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© (ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©) ---
        if browser_instance:
            await browser_instance.close()
            print("ğŸ”’ ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ØªØµÙØ­ Ø¨Ù†Ø¬Ø§Ø­ ÙˆØªØ·Ù‡ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ÙŠØªÙŠÙ…Ø©.")

        # --- Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø±Ù‚Ù… 1: Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… (Chunks) Ù„Ù„Ù‚Ø¨ÙˆÙ„ ÙÙŠ GitHub ---
        if all_movies:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·
            unique_movies = list({m["url"]: m for m in all_movies}.values())
            total_count = len(unique_movies)
            chunk_size = 10000  # ØªÙ‚Ø³ÙŠÙ… ÙƒÙ„ 10 Ø¢Ù„Ø§Ù ÙÙŠ Ù…Ù„Ù

            print(f"ğŸ“¦ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£ÙÙ„Ø§Ù… Ù…Ù† Ù„Ø§Ø±ÙˆØ²Ø§: {total_count}. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªÙ‚Ø³ÙŠÙ…...")

            for i in range(0, total_count, chunk_size):
                chunk = unique_movies[i : i + chunk_size]
                part_num = (i // chunk_size) + 1
                filename = f"laroza_movies_part{part_num}.json"

                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(chunk, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¬Ø²Ø¡ {part_num} ÙÙŠ: {filename}")
        else:
            print("â„¹ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù„Ø§Ø±ÙˆØ²Ø§.")


if __name__ == "__main__":
    asyncio.run(scrape_laroza_movies())
