import asyncio
from playwright.async_api import async_playwright
import json
from datetime import datetime
import re

async def scrape_mycima_series(max_pages=None):
    all_series = [] 
    blacklist = ["+18", "Ù„Ù„ÙƒØ¨Ø§Ø± ÙÙ‚Ø·", "Ø¬Ù†Ø³", "sex", "adult", "18+"]
    
    async with async_playwright() as p:
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªØµÙØ­ Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 800}
        )
        page = await context.new_page()

        # Ø­ÙŠÙ„Ø© Ø³Ø­Ø±ÙŠØ©: Ù…Ù†Ø¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù€ Timeout
        await page.route("**/*.{png,jpg,jpeg,webp,gif}", lambda route: route.abort())

        current_page = 1
        while current_page <= max_pages:
            url = f"https://my-cima.pro/categories-4cima.php?cat=mosalsalat-4Cima-6&page={current_page}&order=DESC"
            print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ ØµÙØ­Ø© {current_page}...")
            
            try:
                # ØªØºÙŠÙŠØ± wait_until Ø¥Ù„Ù‰ 'commit' ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø³Ø­Ø¨ Ø£Ø³Ø±Ø¹ ÙˆÙ„Ø§ ÙŠÙ†ØªØ¸Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
                await page.goto(url, wait_until="commit", timeout=90000)
                
                # Ù†Ù†ØªØ¸Ø± Ø¸Ù‡ÙˆØ± Ø£ÙŠ Ø¹Ù†ØµØ± Ù…Ù† Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ù„Ù…Ø¯Ø© 10 Ø«ÙˆØ§Ù†ÙŠ
                await page.wait_for_selector('li.col-xs-6', timeout=15000)
                
                items = await page.query_selector_all('li.col-xs-6')
                if not items: break

                for item in items:
                    title_tag = await item.query_selector('h3 a')
                    if not title_tag: continue
                    
                    full_title = await title_tag.get_attribute('title')
                    if any(word in full_title.lower() for word in blacklist):
                        continue

                    href = await title_tag.get_attribute('href')
                    img_tag = await item.query_selector('img')
                    image_url = await img_tag.get_attribute('src')
                    
                    clean_name = full_title.replace("Ù…Ø´Ø§Ù‡Ø¯Ø©", "").replace("Ù…Ø§ÙŠ Ø³ÙŠÙ…Ø§", "").strip()
                    year_match = re.search(r'(\d{4})', clean_name)
                    year = int(year_match.group(1)) if year_match else 2025
                    
                    all_series.append({
                        "name": f"[Ù…Ø³Ù„Ø³Ù„] {clean_name}",
                        "url": href if href.startswith('http') else f"https://my-cima.pro/{href}",
                        "image_url": image_url,
                        "year": year,
                        "genre": "Ù…Ø³Ù„Ø³Ù„Ø§Øª",
                        "rating": 0.0,
                        "createdAt": datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
                    })
                
                print(f"âœ… ØªÙ… Ø³Ø­Ø¨ {len(all_series)} Ù…Ø³Ù„Ø³Ù„ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")
                current_page += 1
                await asyncio.sleep(2) # Ø±Ø§Ø­Ø© Ù„Ù„Ù…ÙˆÙ‚Ø¹

            except Exception as e:
                print(f"âš ï¸ ÙˆØ§Ø¬Ù‡Ù†Ø§ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØµÙØ­Ø© {current_page}: {str(e)[:100]}")
                break

        await browser.close()
        
        if all_series:
            with open('mycima_series.json', 'w', encoding='utf-8') as f:
                json.dump(all_series, f, ensure_ascii=False, indent=4)
            print(f"ğŸ ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­!")

if __name__ == "__main__":
    asyncio.run(scrape_mycima_series())